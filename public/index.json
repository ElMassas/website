[{"content":"","date":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"Ai"},{"content":"","date":null,"permalink":"/categories/ai/","section":"Categories","summary":"","title":"AI"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/","section":"ElMassas","summary":"","title":"ElMassas"},{"content":"","date":null,"permalink":"/tags/openai/","section":"Tags","summary":"","title":"Openai"},{"content":"“Dalai Lama sucking Pope Francis’ tongue in a Parisian Bistro at sunrise.”\nA quote that evokes a seemingly improbable event, well, I say this but if it was a child instead of the Pope it isn’t as unlikely. Yet, despite the likelihood of the event, a visual representation of this event might very well be readily available as soon OpenAI makes SORA generally available for the public. SORA is an AI model that can create an assortment of videos from a text prompt such as the one at the beginning of the article.\nWe live in scary times where armed conflicts are popping up left and right, mass-surveillance is almost ubiquitous, climate change is an ever present threat and nations are falling back to ultra-nationalistic tropes. Sometimes it feels like there isn’t much to be hopeful about, you’re just sitting in your corner of the world trying to make a living, and in comes Artificial Intelligence waltzing through the door, with the threat of completely revolutionizing the world and upending millions and millions of lives.\nAI can be great, and in fact I use it a lot in my day-to-day job as a DevOps engineer, it’s a very powerful helper. However, I won’t lie, I see the potential it has to make many jobs disappear, and to make this point, let us go back to SORA. SORA is a remarkable technological achievement, one that seemingly has notions of physics, context and the different layers that compose a video, hence it appears to be far ahead of the competition with a lot of potential to be unlocked.\nLike with most things in life, there are positives and negatives. There are some positive cases that I can imagine and have seen referenced, such as creating videos for product prototyping, marketing videos, lowering the entry level for careers like video editors, film conception, and surely there will be more cases that I haven’t seen mentioned yet.\nDespite my feelings on the somewhat tepid positives that this AI model might bring, I see more dangers and potential risks than benefits. OpenAI says, rightfully so, that they are concerned about possible abuses of this technology, so they are working with teams and the community to make the product as safe as possible. Additionally, all contents generated by the SORA model will be identified with metadata in the C2PA standard, which I consider dangerous and have already discussed in another article.\nBefore pointing out some of the potential dangers I see in this product, I think it’s important to mention that the technology and knowledge used to create this product seem to be mostly known, in particular Diffusion models. This means it’s information that has been discovered and shared by the developer/scientific community in a somewhat transparent and open manner so that everyone can benefit from it. The technical article published by OpenAI demonstrates this fact, and also indicates that only companies in OpenAI’s position could create this model.\nIn the technical article, the team demonstrated how much computational power matters for this product. “Just” by using more computational resources, they can exponentially improve the quality of the final product. By 32xing the compute resources to produce a video, the quality of the output given the model was substantially more realistic and believable.\nThe negatives are, to me, much clearer. OpenAI is able to utilize these computational resources largely due to their partnership with Microsoft, a privilege that other companies or startups obviously do not have. The code for this and all the other models are not OpenSource, so the larger developer community can’t make sure that the users aren’t being taken advantage of. Furthermore, as is constantly demonstrated in the world of tech, it is impossible to create something without security flaws, and in this case, what will happen when someone exploits this model or improves it and makes it more accessible to the general public so that anyone with a computer can generate the video they want?\nI am very afraid of someone creating pornographic videos about someone they dislike, or combining this technology with other technologies like Deepfake and voice emulation that are becoming increasingly realistic, to create, for example, a video of Donald Trump declaring war on China.\nThe ability to create content that allows for the exponential growth of incredibly realistic misinformation is very scary to me. Even experts in the field have been surprised by the advances made in the field of AI in recent years, and our governments do not have the speed or capacity to regulate this rapid advancement to make it at least ethical, let alone to prevent the possible repercussions of these advances.New jobs will be created, many will be irrevocably altered in negative ways, misinformation will grow and it will become increasingly harder to tell what’s true and what’s not. The world is changing\nPersonally, I have no answer for this subject, and I have not seen any sufficiently satisfactory answer from the community yet, but I see my fear shared by many professionals. I believe that as a society, we have to consider to what extent technological advancement and the way it is achieved are necessary or moral, and until we find consensus on this topic, we will suffer greatly and in ways never seen before. Skynet won’t destroy humanity, but an irresponsible use of AI certainly will.\n","date":"13 March 2024","permalink":"/posts/2024/openai_closed_future/","section":"Posts","summary":"","title":"OpenAI, closed future"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/tags/sora/","section":"Tags","summary":"","title":"Sora"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/tech/","section":"Tags","summary":"","title":"Tech"},{"content":"","date":null,"permalink":"/categories/tech/","section":"Categories","summary":"","title":"Tech"},{"content":"","date":null,"permalink":"/tags/video/","section":"Tags","summary":"","title":"Video"},{"content":"","date":null,"permalink":"/tags/c2pa/","section":"Tags","summary":"","title":"C2PA"},{"content":"Let’s imagine a citizen in China who wishes to anonymously share, for any reason whatsoever, an image of Winnie the Pooh — a character censored in China due to its physical resemblance to President Xi Jinping, who, in terms of character, has little in common with a teddy bear. In the near future, this citizen will face an increased risk of being easily identified by authorities due to new technology.\nC22PA is not a Star Wars robot but a technological standard led by a coalition of companies, including Adobe, BBC, and Microsoft. At first glance, they have the noble aim of combating misinformation and copyright abuses by AI and it’s users, through standardizing information production regarding media content. However, upon closer analysis of the proposed standard and associated communication beyond technical or business jargon, we encounter concerning facts, starting with the coalition’s lack of dialogue with the programming community, activists, and security experts.\nThe internet operates on standards and patterns that enable widespread communication, without programmers and other engineers needing to reinvent the wheel for each device, platform, or network — some examples of these standards among thousands are HTTP, TCP/IP, DNS. In this sense, C2PA will be just another standard — however, its format and usage are incredibly worrying.\nThe C2PA standard maintains a cryptographic record of all changes made to a file. This record includes what is called a file’s Metadata, which may include the device on which the file was created, the location, and the identity of those who created and edited the file — akin to cryptocurrencies. The coalition appears to want to enforce the mandatory implementation of this standard.\nGiven this, we return to the initial hypothetical situation of a dissident citizen living under an oppressive government. Now, the same government would know with greater precision who created the image and all accomplices who may have made some edits, thus exacerbating the machinery of political persecution and oppression of human rights.\nBeyond the persecution of dissidents by tyrants who love honey, or similar entities, there are more concerns for the general population. How might a sexual predator use this new standard to stalk victims? Who will decide what actually constitutes “fake news”? How much of our privacy are we willing to give up to achieve greater security — if this new standard indeed achieves that proposed goal? And what about its execution? How will it be implemented in different countries? Will its use be optional? Will it be possible to share files that do not comply with this standard? There are many concerns, which this article will not cover in it’s entirety.\nThe companies in question are already lobbying the US government to force widespread implementation of this standard, which would compel all modern devices to come factory-equipped with this standard implemented by default. I believe it is important to question what these companies stand to gain from this standard. What will be the business model to make the time and money spent on this project viable?\nCould it be purely for the betterment of humanity, as the coalition claims? I put to you, it is not. A former director of the US National Security Agency (Michael Hayden) once stated: “We kill people based on Metadata”. I believe that no one in good conscience, especially with historical knowledge of these companies’ business practices, would claim that as the objective.\nWe live in an era of misinformation, where it is difficult to discern reality from half-truth, half-truth from lie, reality from fiction. To combat this trend, we need clear solutions, with universal implementation, that do not endanger people’s lives and privacy. C2PA is not one of these solutions.\n","date":"4 March 2024","permalink":"/posts/2024/c2pa_the_omnipresent_snitch/","section":"Posts","summary":"","title":"C2PA the omnipresent snitch"},{"content":"","date":null,"permalink":"/tags/dystopian/","section":"Tags","summary":"","title":"Dystopian"},{"content":"","date":"1 January 0001","permalink":"/posts/2024/theres_more_than_the_git_hub/","section":"Posts","summary":"","title":""},{"content":"","date":"1 January 0001","permalink":"/posts/2024/um_esquerdalhada_vai_ao_mais_liberdade/","section":"Posts","summary":"","title":""},{"content":"","date":null,"permalink":"/tags/elixir/","section":"Tags","summary":"","title":"Elixir"},{"content":"","date":null,"permalink":"/categories/programming/","section":"Categories","summary":"","title":"Programming"},{"content":"","date":null,"permalink":"/tags/wordle/","section":"Tags","summary":"","title":"Wordle"}]